{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-56ea43feb035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mosr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gdal'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gdal, osr\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "from scipy.interpolate import griddata\n",
    "import re\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "TA_da = None\n",
    "EVI_da = None\n",
    "LST_Day_da = None\n",
    "LST_Night_da = None\n",
    "MIN_PATCH_SIZE = 3\n",
    "MAX_PATCH_SIZE = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Files\n",
    "FILE_DICT = {\n",
    "    'EVI' : glob.glob('MODIS_NDVI/MOD13*EVI*.tif'),\n",
    "    'EVI_pixel' : glob.glob('MODIS_NDVI/*pixel_reliability*.tif'),\n",
    "    'EVI_QC' : glob.glob('MODIS_NDVI/*VI_Quality*.tif'),\n",
    "    'TA' : glob.glob('MODIS_TA/MOD14*FireMask*.tif'),\n",
    "    'TA_QC' : glob.glob('MODIS_TA/*QA*.tif'),\n",
    "    'LST_Day' : glob.glob('MODIS_LST_Day/*LST_Day*.tif'),\n",
    "    'LST_Day_QC' : glob.glob('MODIS_LST_Day/*QC_Day*.tif'),\n",
    "    'LST_Night' : glob.glob('MODIS_LST_Night/*LST_Night*.tif'),\n",
    "    'LST_Night_QC' : glob.glob('MODIS_LST_Night/*QC_Night*.tif')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files as xarray DataArrays\n",
    "def open_xarray(data, is_qc=False):\n",
    "    \"\"\"\n",
    "    Opens dataset as an xarray DataArray.\n",
    "    \n",
    "    :param data: key from file_dict\n",
    "    :param file_dict: dictionary of file paths\n",
    "    \n",
    "    :returns: xarray data structure\"\"\"\n",
    "    v = FILE_DICT[data]\n",
    "    pat = r'doy(\\d{7})'\n",
    "    da_list = []\n",
    "    for fp in v:\n",
    "        # extract timestamp from filepath\n",
    "        time = re.findall(pat, fp)[0]\n",
    "        year = int(time[:4])\n",
    "        day = int(time[-3:])\n",
    "        \n",
    "        # open raster\n",
    "        da = xr.open_rasterio(fp)\n",
    "        \n",
    "        # assign time coordinate to raster\n",
    "        dt = (datetime.datetime(year, 1, 1) + datetime.timedelta(day - 1))\n",
    "        da = da.assign_coords(time=dt)\n",
    "        \n",
    "        # add current day to list of rasters\n",
    "        da_list.append(da)\n",
    "    # consolidate rasters\n",
    "    da = xr.concat(da_list, dim='time').squeeze()\n",
    "    \n",
    "    # give raster a name\n",
    "    da.name = data\n",
    "    # apply scale factor\n",
    "    da.values = da.values * eval(da.attrs['scale_factor'])\n",
    "    if not is_qc:\n",
    "        da.values = da.values.astype(float)\n",
    "        no_data = da.attrs['nodatavals'][0]\n",
    "        da.values = (np.ma.masked_equal(da.values, no_data))\n",
    "    \n",
    "    da = da.sortby(da.time)\n",
    "    return da\n",
    "\n",
    "\n",
    "def interp_da(to_interp, interp_like):\n",
    "    \"\"\"\n",
    "    Function intended to perform temporal interpolation on the EVI data.\n",
    "    \n",
    "    :param to_interp: the DataArray to temporally interpolate\n",
    "    :param interp_like: the DataArray with the desired temporal resolution\n",
    "    \n",
    "    :returns: interpolated input DA\n",
    "    \"\"\"\n",
    "    return to_interp.interp({'time':interp_like.time}, method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC_MAP = {\n",
    "    'TA': [0, 4],\n",
    "    'EVI': [0],\n",
    "    'LST_Day': [0],\n",
    "    'LST_Night': [0]\n",
    "}\n",
    "\n",
    "def filter_qa(da_name, qc_da_name):\n",
    "    \"\"\"\n",
    "    Filters pixels from dataset based on QA info found in MODXXA2 User Guide.\n",
    "    \n",
    "    :param da_name: the name of the DataArray found in keys of FILE_DICT\n",
    "    :param qc_da_name: the name of the QC DataArray found in the keys of FILE_DICT\n",
    "    \n",
    "    :returns: filtered dataset\n",
    "    \"\"\"\n",
    "    da = open_xarray(da_name)\n",
    "    qc_da = open_xarray(qc_da_name, is_qc=True)\n",
    "    \n",
    "    qc_filter = QC_MAP[da_name]\n",
    "    \n",
    "    for f in qc_filter:\n",
    "        if da_name == 'TA':\n",
    "            da.values[qc_da.values == f] = np.nan\n",
    "        else:\n",
    "            da.values[qc_da.values != f] = np.nan\n",
    "    \n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    \"\"\"\n",
    "    Loads all datasets, does qa filtering, and interpolates where necessary.\n",
    "    Saves datasets to global variables defined at top of notebook.\n",
    "    \"\"\"\n",
    "    global TA_da\n",
    "    global EVI_da\n",
    "    global LST_Day_da\n",
    "    global LST_Night_da\n",
    "    \n",
    "    TA_da = filter_qa('TA', 'TA_QC')\n",
    "    print('TA loaded')\n",
    "    LST_Day_da = filter_qa('LST_Day', 'LST_Day_QC')\n",
    "    print('LST Day loaded')\n",
    "    LST_Night_da = filter_qa('LST_Night', 'LST_Night_QC')\n",
    "    print('LST Night loaded')\n",
    "    EVI_da = filter_qa('EVI', 'EVI_pixel')\n",
    "    EVI_da = interp_da(EVI_da, TA_da)\n",
    "    print('EVI loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA loaded\n",
      "LST Day loaded\n",
      "LST Night loaded\n",
      "EVI loaded\n"
     ]
    }
   ],
   "source": [
    "load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_good(time, pixel):\n",
    "    \"\"\"\n",
    "    Determines if a pixel is acceptable to add to a non-fire pixel patch.\n",
    "    (ie not NaN in any raster and not a fire pixel (7,8,9)).\n",
    "    \n",
    "    :param time: the time index of the pixel\n",
    "    :param pixel: the spatial index to check\n",
    "    :returns: True or False (pixel is acceptable)\n",
    "    \"\"\"\n",
    "    # check if pixel is a fire pixel\n",
    "    if TA_da.values[time][pixel] in [7, 8, 9]:\n",
    "        return False\n",
    "    \n",
    "    # check if pixel is NaN\n",
    "    for da in [TA_da, EVI_da, LST_Day_da, LST_Night_da]:\n",
    "        if np.isnan(da.values[time][pixel]):\n",
    "            return False\n",
    "    \n",
    "    # pixel passed tests\n",
    "    return True\n",
    "\n",
    "def find_patch(time, curr_pix, patch, found, frontier, patch_size):\n",
    "    \"\"\"\n",
    "    Finds a non-fire patch of pixels as an instance of no fire.\n",
    "    \n",
    "    :param time: raster date index to extract\n",
    "    :param curr_pix: current pixel being processed\n",
    "    :param patch: the patch of pixles being generated, starts as empty list\n",
    "    :param found: list of visited index tuples\n",
    "    :param frontier: list of pixels to invesigate, pass empty to start\n",
    "    :param patch_size: number of pixels to be found for this patch\n",
    "    \n",
    "    :returns: list of tuples of indices in patch\n",
    "    \"\"\"\n",
    "    # add pixel to patch\n",
    "    patch.append(curr_pix)\n",
    "        \n",
    "    #stop when patch is appropriately sized\n",
    "    if len(patch) >= patch_size:\n",
    "        return patch\n",
    "    \n",
    "    #explore pixel neighbors\n",
    "    for i in range(-1,2,1):\n",
    "        for j in range(-1,2,1):\n",
    "            neighbor = (curr_pix[0]+i, curr_pix[1]+j)\n",
    "            # only examine pixel if not already checked\n",
    "            if (neighbor not in found) and pixel_good(time, neighbor):\n",
    "                frontier.append(neighbor)\n",
    "                found.append(neighbor)\n",
    "                \n",
    "    # if no more valid pixels to check, exit\n",
    "    if len(frontier) == 0:\n",
    "        return patch\n",
    "    \n",
    "    # examine next pixel in queue\n",
    "    next_pix = frontier.pop(0)\n",
    "    \n",
    "    # recurse\n",
    "    return find_patch(time, next_pix, patch, found, frontier, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_fire_patches(load_datasets=False):\n",
    "    \"\"\"\n",
    "    Find set of non-fire patches for each day in time-series.\n",
    "    \n",
    "    :param load_datasets: pass True if datasets have not already been loaded\n",
    "    \n",
    "    :returns: dictionary of patch indices (date -> list of patches)\n",
    "    \"\"\"\n",
    "    # set random seed\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # load datasets\n",
    "    if load_datasets:\n",
    "        load_datasets()\n",
    "    \n",
    "    # initialize storage\n",
    "    patches = {}\n",
    "    \n",
    "    # save dimensions of a raster\n",
    "    dim1 = TA_da.shape[1]\n",
    "    dim2 = TA_da.shape[2]\n",
    "    \n",
    "    for time in np.arange(TA_da.shape[0]):\n",
    "        curr_patches = []\n",
    "        found = []\n",
    "        \n",
    "        # find this many distinct patches for this date \n",
    "        for _ in range(np.random.choice(np.arange(2,6), p = [0.35, 0.35, 0.15, 0.15])):\n",
    "                \n",
    "            # choose random patch size\n",
    "            patch_size = 0\n",
    "            while (patch_size < MIN_PATCH_SIZE) or (patch_size > MAX_PATCH_SIZE):\n",
    "                # to see sample distribution generate 1000 samples and plot\n",
    "                patch_size = int(np.random.lognormal(2, 1.75))\n",
    "            \n",
    "            # generate random start point that hasn't yet been chosen\n",
    "            i, j = 0, 0\n",
    "            while (not pixel_good(time, (i,j))) or ((i,j) in found):\n",
    "                i = np.random.choice(np.arange(dim1))\n",
    "                j = np.random.choice(np.arange(dim2))\n",
    "            start = (i,j)\n",
    "\n",
    "            # find a patch\n",
    "            found.append(start)\n",
    "            patch = find_patch(time, start, [], found, [], patch_size)\n",
    "            curr_patches.append(patch)\n",
    "            found.extend(patch)\n",
    "            \n",
    "        # save patches to dictionary\n",
    "        patches[TA_da.time.values[time]] = curr_patches\n",
    "        \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coordinates(y, x):\n",
    "    \"\"\"\n",
    "    Takes a pixel coordinate and transforms to lat, lon.\n",
    "    \n",
    "    :param x: the horizontal coordinate of the pixel\n",
    "    :param y: the vertical coordinate of the pixel\n",
    "    \n",
    "    :returns: lat, lon tuple\"\"\"\n",
    "    ds = gdal.Open(FILE_DICT['TA'][0], gdal.GA_ReadOnly)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    \n",
    "    # extract geotransform values\n",
    "    x_offset, px_w, x_rot, y_offset, y_rot, px_h = gt\n",
    "    \n",
    "    # compute affine position\n",
    "    posX = px_w * x + x_rot * y + x_offset\n",
    "    posY = y_rot * x + px_h * y + y_offset\n",
    "\n",
    "    # shift to the center of the pixel\n",
    "    posX += px_w / 2.0\n",
    "    posY += px_h / 2.0\n",
    "    \n",
    "    # get CRS from dataset \n",
    "    crs = osr.SpatialReference()\n",
    "    crs.ImportFromWkt(ds.GetProjectionRef())\n",
    "    # create lat/long crs with WGS84 datum\n",
    "    crsGeo = osr.SpatialReference()\n",
    "    crsGeo.ImportFromEPSG(4326) # 4326 is the EPSG id of lat/long crs \n",
    "    t = osr.CoordinateTransformation(crs, crsGeo)\n",
    "    (lon, lat, z) = t.TransformPoint(posX, posY)\n",
    "    \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_patches(patches):\n",
    "    # extract dimensions of a pixel\n",
    "    pixel_length = TA_da.attrs['transform'][0]  # length of a pixel in meters\n",
    "    rows = []\n",
    "    \n",
    "    # iterate through patches dict\n",
    "    for k, v in patches.items():\n",
    "        time = k\n",
    "        # iterate through patches \n",
    "        for patch in v:\n",
    "            # extract relevant values from each patch\n",
    "            curr_row = {}\n",
    "            ix = ([p[0] for p in patch], [p[1] for p in patch])\n",
    "            pixel_coords = np.mean(ix, axis=1)\n",
    "            lat, lon = compute_coordinates(*pixel_coords)\n",
    "            curr_row['time'] = time\n",
    "            curr_row['lat'] = lat\n",
    "            curr_row['lon'] = lon\n",
    "            curr_row['area'] = pixel_length**2 * len(patch)\n",
    "            curr_row['lst_day'] = np.mean(LST_Day_da.sel(time=time).values[ix])\n",
    "            curr_row['lst_night'] = np.mean(LST_Night_da.sel(time=time).values[ix])\n",
    "            curr_row['evi'] = np.mean(EVI_da.sel(time=time).values[ix])\n",
    "            curr_row['class'] = 'no_fire'\n",
    "            rows.append(curr_row)\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the patches (code commented because dataset already generated)\n",
    "# patches = find_non_fire_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn extracted data into csv and save\n",
    "# df = extract_data_from_patches(patches)\n",
    "# df.to_csv('non_fire.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('non_fire.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area</th>\n",
       "      <th>lst_day</th>\n",
       "      <th>lst_night</th>\n",
       "      <th>evi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>33.408854</td>\n",
       "      <td>-117.076050</td>\n",
       "      <td>1.373816e+07</td>\n",
       "      <td>307.487500</td>\n",
       "      <td>289.228750</td>\n",
       "      <td>0.216975</td>\n",
       "      <td>no_fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>36.137575</td>\n",
       "      <td>-118.225236</td>\n",
       "      <td>9.530845e+07</td>\n",
       "      <td>306.894414</td>\n",
       "      <td>284.389730</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>no_fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>41.055741</td>\n",
       "      <td>-121.923551</td>\n",
       "      <td>5.452330e+08</td>\n",
       "      <td>300.717102</td>\n",
       "      <td>291.531937</td>\n",
       "      <td>0.398504</td>\n",
       "      <td>no_fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>37.479687</td>\n",
       "      <td>-120.400798</td>\n",
       "      <td>4.121447e+07</td>\n",
       "      <td>322.606667</td>\n",
       "      <td>293.778333</td>\n",
       "      <td>0.166904</td>\n",
       "      <td>no_fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>35.525000</td>\n",
       "      <td>-118.555102</td>\n",
       "      <td>5.151808e+06</td>\n",
       "      <td>307.930000</td>\n",
       "      <td>291.180000</td>\n",
       "      <td>0.362250</td>\n",
       "      <td>no_fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time        lat         lon          area     lst_day   lst_night  \\\n",
       "0  2018-06-26  33.408854 -117.076050  1.373816e+07  307.487500  289.228750   \n",
       "1  2018-06-26  36.137575 -118.225236  9.530845e+07  306.894414  284.389730   \n",
       "2  2018-06-26  41.055741 -121.923551  5.452330e+08  300.717102  291.531937   \n",
       "3  2018-07-04  37.479687 -120.400798  4.121447e+07  322.606667  293.778333   \n",
       "4  2018-07-04  35.525000 -118.555102  5.151808e+06  307.930000  291.180000   \n",
       "\n",
       "        evi    class  \n",
       "0  0.216975  no_fire  \n",
       "1  0.234126  no_fire  \n",
       "2  0.398504  no_fire  \n",
       "3  0.166904  no_fire  \n",
       "4  0.362250  no_fire  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(2, 64), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "\n",
    "df_mat = np.matrix(df)\n",
    "inputs = df_mat[:,1:7]\n",
    "fire = df_mat[:,7]\n",
    "#MLP Classifier Function\n",
    "#solver: 'Adam' works better for bigger datasets\n",
    "#regularization parameter: paper did between 0.8 - 4, and compared results\n",
    "#numofiterations:\n",
    "clf = MLPClassifier(solver='adam', alpha=1, hidden_layer_sizes=(2,64), random_state=1)\n",
    "clf.fit(inputs, fire)\n",
    "#clf.predict(df_mat[1,1:7])\n",
    "\n",
    "\n",
    "#Standardizing test set\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(df)\n",
    "#scaler.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no_fire'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-6c618fa0ddd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"M8[ns]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no_fire'"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['no_fire'], dtype='<U7')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      no_fire\n",
       "1      no_fire\n",
       "2      no_fire\n",
       "3      no_fire\n",
       "4      no_fire\n",
       "        ...   \n",
       "151    no_fire\n",
       "152    no_fire\n",
       "153    no_fire\n",
       "154    no_fire\n",
       "155    no_fire\n",
       "Name: class, Length: 156, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
